{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "import torch\n",
    "\n",
    "model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TemplateError",
     "evalue": "Conversation roles must alternate user/assistant/user/assistant/...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTemplateError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m chat \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m    {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful and honest code assistant expert in JavaScript. Please, provide all answers to programming questions in JavaScript\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      3\u001b[0m    {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a function that computes the set of sums of all contiguous sublists of a given list.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m ]\n\u001b[1;32m      5\u001b[0m extra_message \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m    {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdef foo(lst):\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0m obs \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(chat, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# action = tokenizer.apply_chat_template(extra_message, tokenize=False)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m combined \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mapply_chat_template(chat \u001b[38;5;241m+\u001b[39m extra_message, tokenize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/matx/u/quevedo/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1742\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.apply_chat_template\u001b[0;34m(self, conversation, chat_template, add_generation_prompt, tokenize, padding, truncation, max_length, return_tensors, **tokenizer_kwargs)\u001b[0m\n\u001b[1;32m   1739\u001b[0m \u001b[38;5;66;03m# Compilation function uses a cache to avoid recompiling the same template\u001b[39;00m\n\u001b[1;32m   1740\u001b[0m compiled_template \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compile_jinja_template(chat_template)\n\u001b[0;32m-> 1742\u001b[0m rendered \u001b[38;5;241m=\u001b[39m compiled_template\u001b[38;5;241m.\u001b[39mrender(\n\u001b[1;32m   1743\u001b[0m     messages\u001b[38;5;241m=\u001b[39mconversation, add_generation_prompt\u001b[38;5;241m=\u001b[39madd_generation_prompt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_tokens_map\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m padding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1747\u001b[0m     padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# There's only one sequence here, so \"longest\" makes no sense\u001b[39;00m\n",
      "File \u001b[0;32m/matx/u/quevedo/miniconda3/lib/python3.12/site-packages/jinja2/environment.py:1301\u001b[0m, in \u001b[0;36mTemplate.render\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mconcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_render_func(ctx))  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m-> 1301\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvironment\u001b[38;5;241m.\u001b[39mhandle_exception()\n",
      "File \u001b[0;32m/matx/u/quevedo/miniconda3/lib/python3.12/site-packages/jinja2/environment.py:936\u001b[0m, in \u001b[0;36mEnvironment.handle_exception\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    931\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Exception handling helper.  This is used internally to either raise\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;124;03mrewritten exceptions or return a rendered traceback for the template.\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rewrite_traceback_stack\n\u001b[0;32m--> 936\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m rewrite_traceback_stack(source\u001b[38;5;241m=\u001b[39msource)\n",
      "File \u001b[0;32m<template>:1\u001b[0m, in \u001b[0;36mtop-level template code\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/matx/u/quevedo/miniconda3/lib/python3.12/site-packages/jinja2/sandbox.py:393\u001b[0m, in \u001b[0;36mSandboxedEnvironment.call\u001b[0;34m(_SandboxedEnvironment__self, _SandboxedEnvironment__context, _SandboxedEnvironment__obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m __self\u001b[38;5;241m.\u001b[39mis_safe_callable(__obj):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SecurityError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__obj\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is not safely callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m __context\u001b[38;5;241m.\u001b[39mcall(__obj, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/matx/u/quevedo/miniconda3/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1776\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._compile_jinja_template.<locals>.raise_exception\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_exception\u001b[39m(message):\n\u001b[0;32m-> 1776\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TemplateError(message)\n",
      "\u001b[0;31mTemplateError\u001b[0m: Conversation roles must alternate user/assistant/user/assistant/..."
     ]
    }
   ],
   "source": [
    "\n",
    "chat = [\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful and honest code assistant expert in JavaScript. Please, provide all answers to programming questions in JavaScript\"},\n",
    "   {\"role\": \"user\", \"content\": \"Write a function that computes the set of sums of all contiguous sublists of a given list.\"},\n",
    "]\n",
    "extra_message = [\n",
    "   {\"role\": \"assistant\", \"content\": \"def foo(lst):\"},\n",
    "]\n",
    "obs = tokenizer.apply_chat_template(chat, tokenize=False)\n",
    "# action = tokenizer.apply_chat_template(extra_message, tokenize=False)\n",
    "# combined = tokenizer.apply_chat_template(chat + extra_message, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful and honest code assistant expert in JavaScript. Please, provide all answers to programming questions in JavaScript<|im_end|>\\n<|im_start|>user\\nWrite a function that computes the set of sums of all contiguous sublists of a given list.<|im_end|>\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   27,    91,   320,    62,  9688,    91,    29, 10057,   198,  1639,\n",
       "           389,   257,  7613,   290,  5508,  2438,  8796,  5887,   287, 11933,\n",
       "            13,  4222,    11,  2148,   477,  7429,   284,  8300,  2683,   287,\n",
       "         11933,    27,    91,   320,    62,   437,    91,    29,   198,    27,\n",
       "            91,   320,    62,  9688,    91,    29,  7220,   198, 16594,   257,\n",
       "          2163,   326,   552,  1769,   262,   900,   286, 21784,   286,   477,\n",
       "         48627,   850, 20713,   286,   257,  1813,  1351, 29847,    91,   320,\n",
       "            62,   437,    91,    29,   198]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(obs, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
